左上角一致性评分分布表明模型对真实场景具有较好的一致性，显著高于朴素基准值0.5的标准，表明隐变量重构成功：通过贝叶斯 ELO 算法学习到的选手“潜在实力”与“粉丝忠诚度”，能够非常真实地还原现实中的投票偏好。
右下角展示了从第 1 赛季到第 34 赛季，模型一致性评分的演变。前几个赛季（1-4 赛季）的置信区间非常长，均值相对较低，说明模型对早期赛季的预测不太稳定。这可能是由于早期赛事普遍长度短于后期；随着赛季增加，准确度逐渐趋于稳定并保持在高位。
左下角JS散度图同样说明时间早期（紫色点）有较多高散度点。这说明在早期赛季，模型表现不稳定，经常出现分布扭曲的情况，预测质量较差。后期赛季，大多数黄绿色点能够精准地落在右下角，有高一致性、低散度特性
右上角确定性评分分布表明我们虽然预测得“准”，但它给出的预测分布比较平均。我们的模型保留了较宽的置信空间，这表明模型在预测时考虑了更多的不确定性因素，避免了过度自信的预测结果。
    这可能是比赛人数较多导致，文件夹中另外一个certainty和比赛规模图表示了比赛人数和确定性确实具有一定的负相关性。表明人数越多,竞争越激烈，每个人的的票差距越小，预测时模型也就越不确定。
    另外，我们的数据还具有高稀疏性。在赛季初期，选手的比赛记录非常稀疏。根据 Glicko-2 逻辑，观测越稀疏，选手的评分偏差（Rating Deviation, RD）就越大，在蒙特卡洛模拟中引入更大的随机波动。当 RD 较高时，模型对选手真实实力的“信念”是不稳定的，导致模拟出的淘汰概率 p 分布极其平坦

敏感性分析：
为评估基于贝叶斯 Elo 框架的观众投票估计模型的稳定性与可靠性，我们对四个核心超参数进行了全面的敏感性分析：学习率（K 因子）、Softmax 温度（τ）以及噪声标准差（σ）。每个参数在其基准值上下 ±50% 的范围内变动，以观察其对模型输出的影响。
我们采用以下两个定量指标进行评估：
斯皮尔曼等级相关系数（ρ）：用于衡量在参数扰动下，选手最终排名相对于基准结果的稳定性。
预测一致性（C）：用于评估模型在参数变化下准确识别淘汰结果的能力。
K 因子的影响：当学习率在 32.0 至 64.0 之间变化时，斯皮尔曼相关系数始终维持在 ρ ≥ 0.994。这表明，尽管 K 因子调节了 Elo 评分的收敛速度，但它并未改变由数据所揭示的选手实力基本排序。
Softmax 温度（τ）的影响：温度参数控制概率分布的“锐度”，是所有参数中敏感性最高的。然而，即使在较低的 τ = 50.0 时，排名相关系数仍高于 0.982，且预测一致性得分的波动被严格限制在 ±2.5% 的狭窄范围内。
对随机噪声（σ）的鲁棒性：模型对噪声标准差的变化几乎完全不敏感（ρ = 1.0），表明通过 500 次迭代的蒙特卡洛集成，模型有效平均掉了局部随机扰动，收敛至一个稳定的全局后验分布。
定量证据充分证实：所估计的观众投票比例本质上是由评委打分与淘汰约束之间的协同作用驱动的，而非依赖于任意的参数调优。斯皮尔曼相关系数（ρ）和预测一致性（C）的高度稳定性，确保了该模型在各类竞赛情境下均能可靠地重建公众偏好。