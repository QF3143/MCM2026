左上角一致性评分分布表明模型对真实场景具有较好的一致性，显著高于朴素基准值0.5的标准，表明隐变量重构成功：通过贝叶斯 ELO 算法学习到的选手“潜在实力”与“粉丝忠诚度”，能够非常真实地还原现实中的投票偏好。
右下角展示了从第 1 赛季到第 34 赛季，模型一致性评分的演变。前几个赛季（1-4 赛季）的置信区间非常长，均值相对较低，说明模型对早期赛季的预测不太稳定。这可能是由于早期赛事普遍长度短于后期；随着赛季增加，准确度逐渐趋于稳定并保持在高位。
左下角JS散度图同样说明时间早期（紫色点）有较多高散度点。这说明在早期赛季，模型表现不稳定，经常出现分布扭曲的情况，预测质量较差。后期赛季，大多数黄绿色点能够精准地落在右下角，有高一致性、低散度特性
右上角确定性评分分布表明我们虽然预测得“准”，但它给出的预测分布比较平均。我们的模型保留了较宽的置信空间，这表明模型在预测时考虑了更多的不确定性因素，避免了过度自信的预测结果。
    这可能是比赛人数较多导致，文件夹中另外一个certainty和比赛规模图表示了比赛人数和确定性确实具有一定的负相关性。表明人数越多,竞争越激烈，每个人的的票差距越小，预测时模型也就越不确定。
    另外，我们的数据还具有高稀疏性。在赛季初期，选手的比赛记录非常稀疏。根据 Glicko-2 逻辑，观测越稀疏，选手的评分偏差（Rating Deviation, RD）就越大，在蒙特卡洛模拟中引入更大的随机波动。当 RD 较高时，模型对选手真实实力的“信念”是不稳定的，导致模拟出的淘汰概率 p 分布极其平坦
