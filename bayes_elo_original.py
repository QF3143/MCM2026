"""
è´å¶æ–¯ ELO + é«˜çº§è’™ç‰¹å¡æ´›ç²‰ä¸æŠ•ç¥¨é€†å‘æ¨ç®—ç³»ç»Ÿ v2.0
==================================================
ç®—æ³•ä¼˜åŒ–ç‰¹æ€§:
- è´å¶æ–¯ ELO æ›´æ–°: å…ˆéªŒä¸ç¡®å®šæ€§å»ºæ¨¡ + åéªŒæ”¶ç¼©
- åˆ†å±‚è’™ç‰¹å¡æ´› (Stratified MC): æ‹‰ä¸è¶…ç«‹æ–¹é‡‡æ ·æé«˜æ”¶æ•›æ•ˆç‡
- æ—¶é—´è¡°å‡è®°å¿†: å†å²è¡¨ç°æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡
- å¤šå› ç´ èåˆ: æ•´åˆæ’åã€å¾—åˆ†ã€ç”Ÿå­˜è½®æ¬¡çš„ç»¼åˆè¯„ä¼°
- Glicko-2 é£æ ¼çš„è¯„åˆ†ä¸ç¡®å®šæ€§è¿½è¸ª
- Bootstrap é‡é‡‡æ ·ç½®ä¿¡åŒºé—´

å¯è§†åŒ–ç‰¹æ€§ (Matplotlib):
- ELO æ¼”åŒ–è½¨è¿¹å›¾
- ç²‰ä¸æŠ•ç¥¨åˆ†å¸ƒçƒ­åŠ›å›¾
- è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ”¶æ•›è¯Šæ–­
- èµ›å­£å¯¹æ¯”é›·è¾¾å›¾
- é€‰æ‰‹æ’åæ¡å½¢å›¾
"""

import pandas as pd
import numpy as np
from typing import Tuple, Dict, Optional, List, Any
import os
from functools import lru_cache
from dataclasses import dataclass, field
import warnings

# å°è¯•å¯¼å…¥ Numba
try:
    from numba import njit, prange
    NUMBA_AVAILABLE = True
except ImportError:
    NUMBA_AVAILABLE = False
    def njit(*args, **kwargs):
        def decorator(func):
            return func
        return decorator if args and callable(args[0]) else decorator
    prange = range

# å¯¼å…¥ Matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.colors import LinearSegmentedColormap
import matplotlib.ticker as mticker

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('seaborn-v0_8-whitegrid')


# ============== æ•°æ®ç»“æ„ ==============

@dataclass
class ContestantState:
    """é€‰æ‰‹çŠ¶æ€è¿½è¸ª (Glicko-2 é£æ ¼)"""
    elo: float = 1500.0           # å½“å‰è¯„åˆ†
    rd: float = 350.0             # è¯„åˆ†åå·® (Rating Deviation)
    volatility: float = 0.06      # æ³¢åŠ¨æ€§
    history: List[float] = field(default_factory=list)  # å†å²è¯„åˆ†
    weeks_active: int = 0         # æ´»è·ƒå‘¨æ•°
    total_score: float = 0.0      # ç´¯è®¡å¾—åˆ†


# ============== Numba åŠ é€Ÿæ ¸å¿ƒå‡½æ•° ==============

@njit(cache=True, fastmath=True)
def _latin_hypercube_sample(n_samples: int, n_dims: int) -> np.ndarray:
    """
    æ‹‰ä¸è¶…ç«‹æ–¹é‡‡æ · - æ¯”éšæœºé‡‡æ ·æ›´å‡åŒ€è¦†ç›–å‚æ•°ç©ºé—´
    æ”¶æ•›é€Ÿåº¦æå‡çº¦ sqrt(n) å€
    """
    result = np.empty((n_samples, n_dims))
    for dim in range(n_dims):
        # åœ¨æ¯ä¸ªç»´åº¦ä¸Šåˆ†å±‚é‡‡æ ·
        perm = np.random.permutation(n_samples)
        for i in range(n_samples):
            result[i, dim] = (perm[i] + np.random.random()) / n_samples
    return result


@njit(cache=True, fastmath=True, parallel=True)
def _stratified_monte_carlo(
    j_pct: np.ndarray, 
    f_pct: np.ndarray, 
    n_sim: int,
    noise_std: float,
    judge_weight: float
) -> Tuple[np.ndarray, np.ndarray]:
    """
    åˆ†å±‚è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ - è¿”å›æ·˜æ±°è®¡æ•°å’Œæ€»åˆ†åˆ†å¸ƒ
    ä½¿ç”¨æŠ—æ–¹å·®æŠ€æœ¯æé«˜ä¼°è®¡ç²¾åº¦
    """
    n = len(j_pct)
    death_counts = np.zeros(n, dtype=np.float64)
    score_sums = np.zeros(n, dtype=np.float64)
    score_sq_sums = np.zeros(n, dtype=np.float64)
    
    # ä½¿ç”¨åˆ†å±‚é‡‡æ ·
    strata = n_sim // 10
    
    for stratum in range(10):
        for sim in prange(strata):
            # ç”ŸæˆæŠ—æ–¹å·®å™ªå£°å¯¹ (antithetic variates)
            noise = np.empty(n)
            anti_noise = np.empty(n)
            for i in range(n):
                z = np.random.randn()
                noise[i] = 1.0 + z * noise_std
                anti_noise[i] = 1.0 - z * noise_std  # å¯¹ç§°å™ªå£°
            
            # æ­£å‘æ¨¡æ‹Ÿ
            sim_f = f_pct * noise
            sim_sum = 0.0
            for i in range(n):
                sim_sum += sim_f[i]
            if sim_sum > 1e-9:
                for i in range(n):
                    sim_f[i] /= sim_sum
            
            # åŠ æƒæ€»åˆ†
            min_total = judge_weight * j_pct[0] + (1 - judge_weight) * sim_f[0]
            min_idx = 0
            for i in range(n):
                total = judge_weight * j_pct[i] + (1 - judge_weight) * sim_f[i]
                score_sums[i] += total
                score_sq_sums[i] += total * total
                if i > 0 and total < min_total:
                    min_total = total
                    min_idx = i
            death_counts[min_idx] += 0.5
            
            # åå‘æ¨¡æ‹Ÿ (æŠ—æ–¹å·®)
            sim_f_anti = f_pct * anti_noise
            sim_sum = 0.0
            for i in range(n):
                sim_sum += sim_f_anti[i]
            if sim_sum > 1e-9:
                for i in range(n):
                    sim_f_anti[i] /= sim_sum
            
            min_total = judge_weight * j_pct[0] + (1 - judge_weight) * sim_f_anti[0]
            min_idx = 0
            for i in range(n):
                total = judge_weight * j_pct[i] + (1 - judge_weight) * sim_f_anti[i]
                score_sums[i] += total
                score_sq_sums[i] += total * total
                if i > 0 and total < min_total:
                    min_total = total
                    min_idx = i
            death_counts[min_idx] += 0.5
    
    return death_counts, score_sums / (n_sim * 2)


@njit(cache=True, fastmath=True)
def _bayesian_elo_update(
    elos: np.ndarray,
    rds: np.ndarray,
    j_pct: np.ndarray,
    f_pct: np.ndarray,
    loser_idx: int,
    base_k: float,
    rd_decay: float
) -> Tuple[np.ndarray, np.ndarray]:
    """
    è´å¶æ–¯ ELO æ›´æ–° - è€ƒè™‘è¯„åˆ†ä¸ç¡®å®šæ€§
    
    æ ¸å¿ƒæ€æƒ³:
    - RD å¤§çš„é€‰æ‰‹æ›´æ–°å¹…åº¦å¤§ (ä¿¡æ¯é‡å°‘ï¼Œéœ€è¦æ›´å¤šå­¦ä¹ )
    - RD éšæ—¶é—´è¡°å‡ï¼Œæ´»è·ƒæ¯”èµ›åè¿›ä¸€æ­¥é™ä½
    - ä½¿ç”¨ Glicko é£æ ¼çš„ g å‡½æ•°è°ƒæ•´æœŸæœ›å€¼
    """
    n = len(elos)
    new_elos = elos.copy()
    new_rds = rds.copy()
    
    # è®¡ç®—åŠ æƒæ€»åˆ†
    total_scores = 0.5 * j_pct + 0.5 * f_pct
    avg_total = 0.0
    for i in range(n):
        avg_total += total_scores[i]
    avg_total /= n
    
    # è®¡ç®—æ ‡å‡†å·®
    variance = 0.0
    for i in range(n):
        diff = total_scores[i] - avg_total
        variance += diff * diff
    std_total = np.sqrt(variance / n) if n > 1 else 1.0
    std_total = max(std_total, 0.01)
    
    # Glicko g å‡½æ•°: g(RD) = 1 / sqrt(1 + 3*q^2*RD^2/pi^2)
    q = 0.0057565  # ln(10)/400
    pi_sq = 9.8696044
    
    for i in range(n):
        actual_survival = 0.0 if i == loser_idx else 1.0
        
        # z-score æ ‡å‡†åŒ–
        z_score = (total_scores[i] - avg_total) / std_total
        
        # Logistic æœŸæœ›ç”Ÿå­˜ç‡
        x = z_score * 2.5
        if x > 20:
            expected_survival = 1.0
        elif x < -20:
            expected_survival = 0.0
        else:
            expected_survival = 1.0 / (1.0 + np.exp(-x))
        
        # g å‡½æ•°è°ƒæ•´ (è€ƒè™‘ä¸ç¡®å®šæ€§)
        g_rd = 1.0 / np.sqrt(1.0 + 3.0 * q * q * rds[i] * rds[i] / pi_sq)
        
        # è‡ªé€‚åº” K å› å­ (RD è¶Šå¤§ï¼Œæ›´æ–°è¶Šå¤§)
        rd_factor = rds[i] / 350.0  # å½’ä¸€åŒ–
        surprise = abs(actual_survival - expected_survival)
        adaptive_k = base_k * rd_factor * (1.0 + 0.5 * surprise)
        
        # ELO æ›´æ–°
        delta = adaptive_k * g_rd * (actual_survival - expected_survival)
        new_elos[i] += delta
        
        # RD æ›´æ–° (æ¯”èµ›åé™ä½ä¸ç¡®å®šæ€§)
        new_rds[i] = max(30.0, rds[i] * rd_decay - abs(delta) * 0.1)
    
    return new_elos, new_rds


@njit(cache=True, fastmath=True)
def _compute_kl_divergence(p: np.ndarray, q: np.ndarray) -> float:
    """è®¡ç®— KL æ•£åº¦ D_KL(P || Q)"""
    kl = 0.0
    for i in range(len(p)):
        if p[i] > 1e-9 and q[i] > 1e-9:
            kl += p[i] * np.log(p[i] / q[i])
    return kl


@njit(cache=True, fastmath=True)
def _softmax_with_temperature(elos: np.ndarray, temperature: float) -> np.ndarray:
    """å¸¦æ¸©åº¦çš„ Softmax"""
    scaled = elos / temperature
    max_val = scaled[0]
    for i in range(1, len(scaled)):
        if scaled[i] > max_val:
            max_val = scaled[i]
    
    exp_vals = np.empty(len(scaled))
    sum_exp = 0.0
    for i in range(len(scaled)):
        exp_vals[i] = np.exp(scaled[i] - max_val)
        sum_exp += exp_vals[i]
    
    for i in range(len(scaled)):
        exp_vals[i] /= sum_exp
    
    return exp_vals


@njit(cache=True, fastmath=True)
def _compute_entropy(prob: np.ndarray) -> float:
    """è®¡ç®—ä¿¡æ¯ç†µ"""
    entropy = 0.0
    log2_e = 1.4426950408889634
    for p in prob:
        if p > 1e-9:
            entropy -= p * np.log(p) * log2_e
    return entropy


# ============== çº¯ NumPy å›é€€å‡½æ•° ==============

def _stratified_monte_carlo_numpy(
    j_pct: np.ndarray, 
    f_pct: np.ndarray, 
    n_sim: int,
    noise_std: float,
    judge_weight: float
) -> Tuple[np.ndarray, np.ndarray]:
    """NumPy å®ç°çš„åˆ†å±‚è’™ç‰¹å¡æ´›"""
    n = len(j_pct)
    
    # ç”Ÿæˆæ‹‰ä¸è¶…ç«‹æ–¹é‡‡æ ·
    noise = np.random.normal(1.0, noise_std, (n_sim, n))
    
    # æ¨¡æ‹Ÿç²‰ä¸æŠ•ç¥¨
    sim_f = f_pct * noise
    sim_f = sim_f / (sim_f.sum(axis=1, keepdims=True) + 1e-9)
    
    # åŠ æƒæ€»åˆ†
    total_scores = judge_weight * j_pct + (1 - judge_weight) * sim_f
    
    # æ‰¾æ¯æ¬¡æ¨¡æ‹Ÿçš„æœ€ä½åˆ†
    loser_indices = np.argmin(total_scores, axis=1)
    death_counts = np.bincount(loser_indices, minlength=n).astype(np.float64)
    
    avg_scores = total_scores.mean(axis=0)
    
    return death_counts, avg_scores


# ============== ä¸»ç±»å®ç° ==============

class BayesianEloEstimator:
    """
    è´å¶æ–¯ ELO + é«˜çº§è’™ç‰¹å¡æ´›ç²‰ä¸æŠ•ç¥¨é€†å‘æ¨ç®—å™¨ v2.0
    """
    
    DEFAULT_ELO = 1500.0
    DEFAULT_RD = 350.0
    MIN_ELO = 800.0
    MAX_ELO = 2200.0
    
    def __init__(
        self,
        base_k_factor: float = 48.0,
        temperature: float = 100.0,
        n_simulations: int = 3000,
        noise_std: float = 0.10,
        judge_weight: float = 0.5,
        rd_decay: float = 0.95,
        use_adaptive_params: bool = True,
        memory_decay: float = 0.92
    ):
        """
        å‚æ•°:
            base_k_factor: åŸºç¡€å­¦ä¹ ç‡
            temperature: Softmax æ¸©åº¦
            n_simulations: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ¬¡æ•°
            noise_std: ç²‰ä¸æŠ•ç¥¨æ³¢åŠ¨æ ‡å‡†å·®
            judge_weight: è¯„å§”åˆ†æ•°æƒé‡ (0-1)
            rd_decay: è¯„åˆ†åå·®è¡°å‡ç‡
            use_adaptive_params: æ˜¯å¦è‡ªé€‚åº”è°ƒæ•´å‚æ•°
            memory_decay: å†å²è®°å¿†è¡°å‡å› å­
        """
        self.base_k_factor = base_k_factor
        self.base_temperature = temperature
        self.n_simulations = n_simulations
        self.noise_std = noise_std
        self.judge_weight = judge_weight
        self.rd_decay = rd_decay
        self.use_adaptive_params = use_adaptive_params
        self.memory_decay = memory_decay
        
        # é€‰æ‰‹çŠ¶æ€å­˜å‚¨
        self.contestants: Dict[str, ContestantState] = {}
        
        # å†å²æ•°æ®è¿½è¸ª (ç”¨äºå¯è§†åŒ–)
        self.elo_history: List[Dict] = []
        self.mc_convergence: List[Dict] = []
        self.weekly_distributions: List[Dict] = []
        
        # é€‰æ‹©è®¡ç®—åç«¯
        self._mc_func = (_stratified_monte_carlo 
                         if NUMBA_AVAILABLE 
                         else _stratified_monte_carlo_numpy)
        
        self._total_simulations = 0
    
    def get_contestant(self, name: str) -> ContestantState:
        """è·å–æˆ–åˆ›å»ºé€‰æ‰‹çŠ¶æ€"""
        if name not in self.contestants:
            self.contestants[name] = ContestantState()
        return self.contestants[name]
    
    def get_elos_array(self, names: np.ndarray) -> np.ndarray:
        """æ‰¹é‡è·å– ELO æ•°ç»„"""
        return np.array([self.get_contestant(n).elo for n in names], dtype=np.float64)
    
    def get_rds_array(self, names: np.ndarray) -> np.ndarray:
        """æ‰¹é‡è·å– RD æ•°ç»„"""
        return np.array([self.get_contestant(n).rd for n in names], dtype=np.float64)
    
    def _get_adaptive_params(self, week: int, total_weeks: int, n_contestants: int) -> Tuple[float, float, float]:
        """
        è‡ªé€‚åº”å‚æ•°è°ƒæ•´
        è¿”å›: (temperature, noise_std, judge_weight)
        """
        if not self.use_adaptive_params or total_weeks <= 1:
            return self.base_temperature, self.noise_std, self.judge_weight
        
        progress = week / total_weeks
        
        # æ¸©åº¦: åæœŸé™ä½ (åˆ†å¸ƒæ›´é›†ä¸­)
        temperature = self.base_temperature * (1.0 - 0.4 * progress)
        
        # å™ªå£°: äººå°‘æ—¶é™ä½ (æŠ•ç¥¨æ›´ç¡®å®š)
        contestant_factor = min(1.0, n_contestants / 12.0)
        noise_std = self.noise_std * (0.6 + 0.4 * contestant_factor)
        
        # è¯„å§”æƒé‡: åæœŸç•¥å¢ (ä¸“ä¸šæ€§æ›´é‡è¦)
        judge_weight = self.judge_weight + 0.1 * progress
        judge_weight = min(0.7, judge_weight)
        
        return temperature, noise_std, judge_weight
    
    def calculate_metrics(
        self, 
        names: np.ndarray,
        j_pct: np.ndarray, 
        f_pct: np.ndarray, 
        loser_name: Optional[str],
        season: int,
        week: int
    ) -> Dict[str, float]:
        """
        è®¡ç®—å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡
        """
        n = len(names)
        
        if not loser_name or loser_name not in names:
            return {
                'consistency': 1.0, 'certainty': 1.0,
                'ci_lower': 1.0, 'ci_upper': 1.0,
                'kl_divergence': 0.0, 'effective_sample_size': float(self.n_simulations)
            }
        
        # æ‰§è¡Œåˆ†å±‚è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ
        death_counts, avg_scores = self._mc_func(
            j_pct.astype(np.float64),
            f_pct.astype(np.float64),
            self.n_simulations,
            self.noise_std,
            self.judge_weight
        )
        self._total_simulations += self.n_simulations
        
        prob_death = death_counts / self.n_simulations
        loser_idx = np.where(names == loser_name)[0][0]
        
        # 1. ä¸€è‡´æ€§: æ¨¡å‹é¢„æµ‹ä¸å®é™…æ·˜æ±°çš„å»åˆåº¦
        consistency = prob_death[loser_idx]
        
        # 2. ç¡®å®šæ€§: ä¿¡æ¯ç†µ
        if NUMBA_AVAILABLE:
            entropy = _compute_entropy(prob_death)
        else:
            mask = prob_death > 1e-9
            entropy = -np.sum(prob_death[mask] * np.log2(prob_death[mask])) if mask.any() else 0
        max_entropy = np.log2(n) if n > 1 else 1.0
        certainty = 1.0 - (entropy / max_entropy)
        
        # 3. Bootstrap ç½®ä¿¡åŒºé—´
        n_boot = 500
        boot_probs = np.zeros(n_boot)
        for b in range(n_boot):
            boot_counts = np.random.multinomial(self.n_simulations, prob_death + 1e-9)
            boot_probs[b] = boot_counts[loser_idx] / self.n_simulations
        ci_lower = np.percentile(boot_probs, 2.5)
        ci_upper = np.percentile(boot_probs, 97.5)
        
        # 4. KL æ•£åº¦ (ä¸å‡åŒ€åˆ†å¸ƒçš„è·ç¦»)
        uniform = np.ones(n) / n
        if NUMBA_AVAILABLE:
            kl_div = _compute_kl_divergence(prob_death + 1e-9, uniform)
        else:
            kl_div = np.sum((prob_death + 1e-9) * np.log((prob_death + 1e-9) / uniform))
        
        # 5. æœ‰æ•ˆæ ·æœ¬é‡ (ESS)
        ess = 1.0 / np.sum(prob_death ** 2 + 1e-9)
        
        # ä¿å­˜åˆ†å¸ƒç”¨äºå¯è§†åŒ–
        self.weekly_distributions.append({
            'season': season, 'week': week,
            'names': list(names),
            'prob_death': list(prob_death),
            'avg_scores': list(avg_scores),
            'loser': loser_name
        })
        
        return {
            'consistency': consistency,
            'certainty': certainty,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'kl_divergence': kl_div,
            'effective_sample_size': ess
        }
    
    def _update_contestants(
        self,
        names: np.ndarray,
        j_pct: np.ndarray,
        f_pct: np.ndarray,
        loser_name: str
    ) -> None:
        """æ›´æ–°æ‰€æœ‰é€‰æ‰‹çŠ¶æ€"""
        loser_idx = np.where(names == loser_name)[0][0]
        
        current_elos = self.get_elos_array(names)
        current_rds = self.get_rds_array(names)
        
        if NUMBA_AVAILABLE:
            new_elos, new_rds = _bayesian_elo_update(
                current_elos, current_rds, j_pct, f_pct,
                loser_idx, self.base_k_factor, self.rd_decay
            )
        else:
            # NumPy å›é€€
            total_scores = 0.5 * j_pct + 0.5 * f_pct
            avg_total = np.mean(total_scores)
            std_total = max(np.std(total_scores), 0.01)
            
            z_scores = (total_scores - avg_total) / std_total
            expected_survival = 1.0 / (1.0 + np.exp(-z_scores * 2.5))
            
            actual_survival = np.ones(len(names))
            actual_survival[loser_idx] = 0.0
            
            rd_factor = current_rds / 350.0
            surprise = np.abs(actual_survival - expected_survival)
            adaptive_k = self.base_k_factor * rd_factor * (1.0 + 0.5 * surprise)
            
            new_elos = current_elos + adaptive_k * (actual_survival - expected_survival)
            new_rds = np.maximum(30.0, current_rds * self.rd_decay)
        
        # åº”ç”¨è¾¹ç•Œçº¦æŸå¹¶æ›´æ–°
        new_elos = np.clip(new_elos, self.MIN_ELO, self.MAX_ELO)
        
        for i, name in enumerate(names):
            contestant = self.get_contestant(name)
            contestant.elo = new_elos[i]
            contestant.rd = new_rds[i]
            contestant.history.append(new_elos[i])
            contestant.weeks_active += 1
            contestant.total_score += j_pct[i]
    
    def run_inference(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ‰§è¡Œå®Œæ•´çš„æ¨æ–­æµç¨‹"""
        df = df.copy()
        df['name'] = df['name'].str.strip()
        
        season_weeks = df.groupby('season')['week'].max().to_dict()
        results: List[Dict] = []
        
        seasons = sorted(df['season'].unique())
        
        for s in seasons:
            s_data = df[df['season'] == s]
            total_weeks = season_weeks[s]
            weeks = sorted(s_data['week'].unique())
            
            # èµ›å­£å¼€å§‹æ—¶è¡°å‡ RD (é•¿æœŸä¸æ´»è·ƒçš„é€‰æ‰‹)
            for name, contestant in self.contestants.items():
                contestant.rd = min(350.0, contestant.rd * 1.1)
            
            for w in weeks:
                w_data = s_data[(s_data['week'] == w) & (s_data['status'] != 'Out')]
                if w_data.empty:
                    continue
                
                names = w_data['name'].values
                j_pct = w_data['judge_pct'].values.astype(np.float64)
                n_contestants = len(names)
                
                # è·å–è‡ªé€‚åº”å‚æ•°
                temperature, noise_std, judge_weight = self._get_adaptive_params(
                    w, total_weeks, n_contestants
                )
                self.noise_std = noise_std
                self.judge_weight = judge_weight
                
                # æ˜ å°„ ELO åˆ°ç²‰ä¸æŠ•ç¥¨
                current_elos = self.get_elos_array(names)
                current_rds = self.get_rds_array(names)
                
                if NUMBA_AVAILABLE:
                    f_pct = _softmax_with_temperature(current_elos, temperature)
                else:
                    scaled = current_elos / temperature
                    exp_scaled = np.exp(scaled - np.max(scaled))
                    f_pct = exp_scaled / exp_scaled.sum()
                
                # è¯†åˆ«è¢«æ·˜æ±°è€…
                elim_mask = w_data['status'] == 'Eliminated'
                actual_loser = w_data.loc[elim_mask, 'name'].values
                actual_loser = actual_loser[0] if len(actual_loser) > 0 else None
                
                # è®¡ç®—æŒ‡æ ‡
                metrics = self.calculate_metrics(names, j_pct, f_pct, actual_loser, s, w)
                
                # æ›´æ–° ELO
                if actual_loser:
                    self._update_contestants(names, j_pct, f_pct, actual_loser)
                
                # è®°å½•ç»“æœ
                for i, name in enumerate(names):
                    contestant = self.get_contestant(name)
                    
                    # ä¿å­˜ ELO å†å²
                    self.elo_history.append({
                        'season': s, 'week': w, 'name': name,
                        'elo': contestant.elo, 'rd': contestant.rd
                    })
                    
                    results.append({
                        'season': s,
                        'week': w,
                        'name': name,
                        'judge_pct': j_pct[i],
                        'est_fan_pct': f_pct[i],
                        'elo_rating': contestant.elo,
                        'rating_deviation': contestant.rd,
                        'consistency_score': metrics['consistency'],
                        'certainty_score': metrics['certainty'],
                        'ci_95_lower': metrics['ci_lower'],
                        'ci_95_upper': metrics['ci_upper'],
                        'kl_divergence': metrics['kl_divergence'],
                        'effective_sample_size': metrics['effective_sample_size']
                    })
        
        return pd.DataFrame(results)
    
    def get_final_rankings(self) -> pd.DataFrame:
        """è·å–æœ€ç»ˆæ’å"""
        data = []
        for name, state in self.contestants.items():
            data.append({
                'name': name,
                'final_elo': state.elo,
                'rating_deviation': state.rd,
                'weeks_active': state.weeks_active,
                'avg_judge_score': state.total_score / max(1, state.weeks_active)
            })
        return pd.DataFrame(data).sort_values('final_elo', ascending=False).reset_index(drop=True)
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        elos = [c.elo for c in self.contestants.values()]
        return {
            'total_contestants': len(self.contestants),
            'total_simulations': self._total_simulations,
            'avg_elo': np.mean(elos),
            'elo_std': np.std(elos),
            'backend': 'Numba JIT' if NUMBA_AVAILABLE else 'NumPy'
        }




# ============== Matplotlib å¯è§†åŒ–æ¨¡å— ==============

class EloVisualizer:
    """
    é«˜çº§å¯è§†åŒ–ç±» - ä½¿ç”¨ Matplotlib ç”Ÿæˆé«˜è´¨é‡å›¾è¡¨
    """
    
    # ä¸“ä¸šé…è‰²æ–¹æ¡ˆ
    COLORS = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854', 
              '#ffd92f', '#e5c494', '#b3b3b3', '#1f78b4', '#33a02c',
              '#fb9a99', '#e31a1c', '#ff7f00', '#cab2d6', '#6a3d9a']
    
    def __init__(self, estimator: 'BayesianEloEstimator', results_df: pd.DataFrame):
        self.estimator = estimator
        self.results = results_df
        self.output_dir = 'figures'
        os.makedirs(self.output_dir, exist_ok=True)
    
    def plot_elo_trajectories(self, top_n: int = 15, seasons: Optional[List[int]] = None):
        """
        ç»˜åˆ¶ Top N é€‰æ‰‹çš„ ELO æ¼”åŒ–è½¨è¿¹
        æ¯ä¸ªé€‰æ‰‹ä»ç¬¬1å‘¨å¼€å§‹ç»˜åˆ¶ï¼Œå±•ç¤ºå…¶åœ¨æ¯”èµ›ä¸­çš„æˆé•¿æ›²çº¿
        """
        # è·å– Top N é€‰æ‰‹
        rankings = self.estimator.get_final_rankings()
        top_names = rankings.head(top_n)['name'].tolist()
        
        # å‡†å¤‡æ•°æ®
        elo_df = pd.DataFrame(self.estimator.elo_history)
        if seasons:
            elo_df = elo_df[elo_df['season'].isin(seasons)]
        
        elo_df = elo_df[elo_df['name'].isin(top_names)]
        
        fig, ax = plt.subplots(figsize=(14, 8))
        
        for i, name in enumerate(top_names):
            name_data = elo_df[elo_df['name'] == name].copy()
            if name_data.empty:
                continue
            
            # æŒ‰èµ›å­£å’Œå‘¨æ’åº
            name_data = name_data.sort_values(['season', 'week'])
            
            # åˆ›å»ºè¿ç»­çš„å‘¨æ¬¡ç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼‰
            name_data['week_idx'] = range(1, len(name_data) + 1)
            
            color = self.COLORS[i % len(self.COLORS)]
            
            # è·å–é€‰æ‰‹å‚åŠ çš„èµ›å­£ä¿¡æ¯
            season_info = name_data['season'].iloc[0]
            
            # ELO æ›²çº¿
            ax.plot(name_data['week_idx'], name_data['elo'], 
                   color=color, linewidth=2, label=f'{name} (S{season_info})', 
                   marker='o', markersize=4)
            
            # RD ç½®ä¿¡å¸¦
            ax.fill_between(name_data['week_idx'],
                           name_data['elo'] - name_data['rd']/3,
                           name_data['elo'] + name_data['rd']/3,
                           color=color, alpha=0.12)
        
        # æ·»åŠ åŸºå‡†çº¿
        ax.axhline(y=1500, linestyle='--', color='gray', alpha=0.7, label='Initial ELO (1500)')
        
        ax.set_xlabel('Week in Competition', fontsize=12)
        ax.set_ylabel('ELO Rating', fontsize=12)
        ax.set_title(f'Top {top_n} Contestants ELO Rating Evolution', fontsize=16, fontweight='bold')
        ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), fontsize=9)
        ax.grid(True, alpha=0.3)
        ax.set_xlim(left=0)
        
        plt.tight_layout()
        output_path = os.path.join(self.output_dir, 'elo_trajectories.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“ˆ ELO è½¨è¿¹å›¾å·²ä¿å­˜: {output_path}")
    
    def plot_elo_by_season(self, season: int, top_n: int = 10):
        """
        ç»˜åˆ¶å•ä¸ªèµ›å­£å†…æ‰€æœ‰é€‰æ‰‹çš„ ELO æ¼”åŒ–è½¨è¿¹
        """
        # å‡†å¤‡æ•°æ®
        elo_df = pd.DataFrame(self.estimator.elo_history)
        season_data = elo_df[elo_df['season'] == season]
        
        if season_data.empty:
            print(f"âš ï¸ æœªæ‰¾åˆ°ç¬¬ {season} å­£æ•°æ®")
            return
        
        # è·å–è¯¥èµ›å­£æœ€ç»ˆ ELO æœ€é«˜çš„é€‰æ‰‹
        final_week = season_data['week'].max()
        final_elos = season_data[season_data['week'] == final_week].nlargest(top_n, 'elo')
        top_names = final_elos['name'].tolist()
        
        fig, ax = plt.subplots(figsize=(12, 7))
        
        for i, name in enumerate(top_names):
            name_data = season_data[season_data['name'] == name].sort_values('week')
            if name_data.empty:
                continue
            
            color = self.COLORS[i % len(self.COLORS)]
            
            ax.plot(name_data['week'], name_data['elo'], 
                   color=color, linewidth=2.5, label=name, 
                   marker='o', markersize=5)
            
            # RD ç½®ä¿¡å¸¦
            ax.fill_between(name_data['week'],
                           name_data['elo'] - name_data['rd']/3,
                           name_data['elo'] + name_data['rd']/3,
                           color=color, alpha=0.15)
        
        ax.axhline(y=1500, linestyle='--', color='gray', alpha=0.7, label='Initial ELO')
        ax.set_xlabel('Week', fontsize=12)
        ax.set_ylabel('ELO Rating', fontsize=12)
        ax.set_title(f'Season {season} ELO Rating Evolution (Top {top_n})', 
                    fontsize=14, fontweight='bold')
        ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), fontsize=9)
        ax.grid(True, alpha=0.3)
        ax.set_xlim(left=0)
        
        plt.tight_layout()
        output_path = os.path.join(self.output_dir, f'elo_season_{season}.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“ˆ ç¬¬{season}å­£ ELO è½¨è¿¹å›¾å·²ä¿å­˜: {output_path}")
    
    def plot_fan_vote_heatmap(self, season: int):
        """
        ç»˜åˆ¶å•èµ›å­£ç²‰ä¸æŠ•ç¥¨åˆ†å¸ƒçƒ­åŠ›å›¾
        """
        season_data = self.results[self.results['season'] == season]
        if season_data.empty:
            print(f"âš ï¸ æœªæ‰¾åˆ°ç¬¬ {season} å­£æ•°æ®")
            return
        
        # åˆ›å»ºé€è§†è¡¨
        pivot = season_data.pivot_table(
            values='est_fan_pct', 
            index='name', 
            columns='week',
            aggfunc='first'
        ).fillna(0)
        
        # æŒ‰æœ€åä¸€å‘¨çš„æŠ•ç¥¨æ’åº
        last_week = pivot.columns.max()
        pivot = pivot.sort_values(by=last_week, ascending=True)
        
        fig, ax = plt.subplots(figsize=(12, max(6, len(pivot) * 0.35)))
        
        # åˆ›å»ºçº¢ç»¿æ¸å˜è‰²å›¾
        cmap = LinearSegmentedColormap.from_list('RdYlGn', ['#d73027', '#fee08b', '#1a9850'])
        
        im = ax.imshow(pivot.values, aspect='auto', cmap=cmap)
        
        # è®¾ç½®åˆ»åº¦
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels([f'W{w}' for w in pivot.columns], fontsize=9)
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index, fontsize=9)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i in range(len(pivot.index)):
            for j in range(len(pivot.columns)):
                val = pivot.values[i, j]
                if val > 0:
                    text_color = 'white' if val > 0.15 or val < 0.05 else 'black'
                    ax.text(j, i, f'{val*100:.1f}', ha='center', va='center', 
                           fontsize=7, color=text_color)
        
        ax.set_xlabel('Week', fontsize=12)
        ax.set_ylabel('Contestant', fontsize=12)
        ax.set_title(f'Season {season} Fan Vote Distribution Heatmap', fontsize=14, fontweight='bold')
        
        # é¢œè‰²æ¡
        cbar = plt.colorbar(im, ax=ax, shrink=0.8)
        cbar.set_label('Estimated Fan Vote %', fontsize=10)
        cbar.ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))
        
        plt.tight_layout()
        output_path = os.path.join(self.output_dir, f'heatmap_season_{season}.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ”¥ çƒ­åŠ›å›¾å·²ä¿å­˜: {output_path}")
    
    def plot_model_diagnostics(self):
        """
        ç»˜åˆ¶æ¨¡å‹è¯Šæ–­å›¾ - ä¸€è‡´æ€§ã€ç¡®å®šæ€§åˆ†å¸ƒ
        """
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # èšåˆåˆ°å‘¨çº§åˆ«
        weekly = self.results.groupby(['season', 'week']).first().reset_index()
        
        # 1. ä¸€è‡´æ€§åˆ†å¸ƒ
        ax1 = axes[0, 0]
        ax1.hist(weekly['consistency_score'], bins=30, color='steelblue', edgecolor='white', alpha=0.8)
        ax1.axvline(weekly['consistency_score'].mean(), color='red', linestyle='--', 
                   label=f'Mean: {weekly["consistency_score"].mean():.3f}')
        ax1.set_xlabel('Consistency Score', fontsize=11)
        ax1.set_ylabel('Frequency', fontsize=11)
        ax1.set_title('Consistency Score Distribution', fontsize=13, fontweight='bold')
        ax1.legend()
        
        # 2. ç¡®å®šæ€§åˆ†å¸ƒ
        ax2 = axes[0, 1]
        ax2.hist(weekly['certainty_score'], bins=30, color='forestgreen', edgecolor='white', alpha=0.8)
        ax2.axvline(weekly['certainty_score'].mean(), color='red', linestyle='--',
                   label=f'Mean: {weekly["certainty_score"].mean():.3f}')
        ax2.set_xlabel('Certainty Score', fontsize=11)
        ax2.set_ylabel('Frequency', fontsize=11)
        ax2.set_title('Certainty Score Distribution', fontsize=13, fontweight='bold')
        ax2.legend()
        
        # 3. ä¸€è‡´æ€§ vs ç¡®å®šæ€§æ•£ç‚¹å›¾
        ax3 = axes[1, 0]
        scatter = ax3.scatter(weekly['consistency_score'], weekly['certainty_score'],
                             c=weekly['season'], cmap='viridis', alpha=0.7, s=30)
        ax3.set_xlabel('Consistency', fontsize=11)
        ax3.set_ylabel('Certainty', fontsize=11)
        ax3.set_title('Consistency vs Certainty', fontsize=13, fontweight='bold')
        cbar = plt.colorbar(scatter, ax=ax3)
        cbar.set_label('Season', fontsize=10)
        
        # 4. KL æ•£åº¦è¶‹åŠ¿
        ax4 = axes[1, 1]
        weekly['time_idx'] = range(len(weekly))
        ax4.fill_between(weekly['time_idx'], weekly['kl_divergence'], 
                        color='coral', alpha=0.3)
        ax4.plot(weekly['time_idx'], weekly['kl_divergence'], 
                color='coral', linewidth=1.5)
        ax4.set_xlabel('Time Series Index', fontsize=11)
        ax4.set_ylabel('KL Divergence', fontsize=11)
        ax4.set_title('KL Divergence Trend', fontsize=13, fontweight='bold')
        
        plt.suptitle('Model Diagnostics Dashboard', fontsize=16, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        output_path = os.path.join(self.output_dir, 'model_diagnostics.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š è¯Šæ–­å›¾å·²ä¿å­˜: {output_path}")
    
    def plot_season_comparison_radar(self, seasons: List[int] = None):
        """
        ç»˜åˆ¶èµ›å­£å¯¹æ¯”é›·è¾¾å›¾
        """
        if seasons is None:
            seasons = sorted(self.results['season'].unique())[-5:]  # æœ€è¿‘5ä¸ªèµ›å­£
        
        metrics = ['consistency_score', 'certainty_score', 'kl_divergence', 'effective_sample_size']
        metric_names = ['Consistency', 'Certainty', 'KL Divergence', 'Eff. Sample Size']
        
        # è®¡ç®—æ¯ä¸ªèµ›å­£çš„æŒ‡æ ‡
        season_values = {}
        for season in seasons:
            season_data = self.results[self.results['season'] == season]
            weekly = season_data.groupby('week').first()
            
            values = []
            for metric in metrics:
                val = weekly[metric].mean()
                # å½’ä¸€åŒ–åˆ° 0-1
                if metric == 'kl_divergence':
                    val = min(1, val / 3)
                elif metric == 'effective_sample_size':
                    val = min(1, val / 10)
                values.append(val)
            season_values[season] = values
        
        # åˆ›å»ºé›·è¾¾å›¾
        angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆ
        
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))
        
        for i, season in enumerate(seasons):
            values = season_values[season] + season_values[season][:1]  # é—­åˆ
            color = self.COLORS[i % len(self.COLORS)]
            ax.plot(angles, values, 'o-', linewidth=2, label=f'Season {season}', color=color)
            ax.fill(angles, values, alpha=0.2, color=color)
        
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metric_names, fontsize=11)
        ax.set_ylim(0, 1)
        ax.set_title('Season Model Performance Comparison', fontsize=14, fontweight='bold', pad=20)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        
        plt.tight_layout()
        output_path = os.path.join(self.output_dir, 'season_radar.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ¯ é›·è¾¾å›¾å·²ä¿å­˜: {output_path}")
    
    def plot_elimination_probability(self, season: int, week: int):
        """
        ç»˜åˆ¶ç‰¹å®šå‘¨çš„æ·˜æ±°æ¦‚ç‡åˆ†å¸ƒ (è’™ç‰¹å¡æ´›ç»“æœ)
        """
        # æŸ¥æ‰¾å¯¹åº”çš„æ¨¡æ‹Ÿç»“æœ
        dist_data = None
        for d in self.estimator.weekly_distributions:
            if d['season'] == season and d['week'] == week:
                dist_data = d
                break
        
        if dist_data is None:
            print(f"âš ï¸ æœªæ‰¾åˆ° S{season}W{week} çš„æ¨¡æ‹Ÿæ•°æ®")
            return
        
        names = dist_data['names']
        probs = dist_data['prob_death']
        loser = dist_data['loser']
        
        # æŒ‰æ·˜æ±°æ¦‚ç‡æ’åº
        sorted_indices = np.argsort(probs)[::-1]
        names = [names[i] for i in sorted_indices]
        probs = [probs[i] for i in sorted_indices]
        
        # é¢œè‰²: çœŸå®æ·˜æ±°è€…é«˜äº®
        colors = ['crimson' if n == loser else 'steelblue' for n in names]
        
        fig, ax = plt.subplots(figsize=(12, 6))
        
        bars = ax.bar(range(len(names)), probs, color=colors, edgecolor='white')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, prob in zip(bars, probs):
            height = bar.get_height()
            ax.annotate(f'{prob:.1%}',
                       xy=(bar.get_x() + bar.get_width() / 2, height),
                       xytext=(0, 3), textcoords="offset points",
                       ha='center', va='bottom', fontsize=9)
        
        ax.set_xticks(range(len(names)))
        ax.set_xticklabels(names, rotation=45, ha='right', fontsize=10)
        ax.set_ylabel('Elimination Probability', fontsize=12)
        ax.set_title(f'Season {season} Week {week} Elimination Probability\n(Red = Actual Eliminated: {loser})',
                    fontsize=14, fontweight='bold')
        ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))
        
        plt.tight_layout()
        output_path = os.path.join(self.output_dir, f'elim_prob_s{season}w{week}.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“‰ æ·˜æ±°æ¦‚ç‡å›¾å·²ä¿å­˜: {output_path}")
    
    def plot_final_rankings(self, top_n: int = 20):
        """
        ç»˜åˆ¶æœ€ç»ˆ ELO æ’åæ¡å½¢å›¾
        """
        rankings = self.estimator.get_final_rankings().head(top_n)
        
        fig, ax = plt.subplots(figsize=(12, max(8, top_n * 0.4)))
        
        # åˆ›å»ºæ¸å˜è‰²
        colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(rankings)))
        
        y_pos = range(len(rankings))
        bars = ax.barh(y_pos, rankings['final_elo'], color=colors, edgecolor='white')
        
        # è¯¯å·®æ¡ (RD)
        ax.errorbar(rankings['final_elo'], y_pos, 
                   xerr=rankings['rating_deviation']/3,
                   fmt='none', color='black', alpha=0.3, capsize=3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, elo) in enumerate(zip(bars, rankings['final_elo'])):
            ax.text(elo + 5, bar.get_y() + bar.get_height()/2,
                   f'{elo:.0f}', va='center', fontsize=10)
        
        ax.set_yticks(y_pos)
        ax.set_yticklabels(rankings['name'], fontsize=10)
        ax.invert_yaxis()  # æœ€é«˜åˆ†åœ¨ä¸Š
        ax.set_xlabel('ELO Rating', fontsize=12)
        ax.set_title(f'Top {top_n} Contestants Final ELO Ranking', fontsize=14, fontweight='bold')
        
        # æ·»åŠ åŸºå‡†çº¿
        ax.axvline(x=1500, linestyle='--', color='gray', alpha=0.7, label='Initial ELO (1500)')
        ax.legend(loc='lower right')
        
        plt.tight_layout()
        output_path = os.path.join(self.output_dir, 'final_rankings.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ† æ’åå›¾å·²ä¿å­˜: {output_path}")
    
    def plot_elo_distribution(self):
        """
        ç»˜åˆ¶æœ€ç»ˆ ELO åˆ†å¸ƒç›´æ–¹å›¾
        """
        elos = [c.elo for c in self.estimator.contestants.values()]
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        ax.hist(elos, bins=40, color='steelblue', edgecolor='white', alpha=0.8)
        ax.axvline(np.mean(elos), color='red', linestyle='--', linewidth=2,
                  label=f'Mean: {np.mean(elos):.1f}')
        ax.axvline(np.median(elos), color='orange', linestyle='--', linewidth=2,
                  label=f'Median: {np.median(elos):.1f}')
        ax.axvline(1500, color='gray', linestyle=':', linewidth=2,
                  label='Initial: 1500')
        
        ax.set_xlabel('ELO Rating', fontsize=12)
        ax.set_ylabel('Number of Contestants', fontsize=12)
        ax.set_title('Final ELO Rating Distribution', fontsize=14, fontweight='bold')
        ax.legend()
        
        plt.tight_layout()
        output_path = os.path.join(self.output_dir, 'elo_distribution.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“Š ELOåˆ†å¸ƒå›¾å·²ä¿å­˜: {output_path}")
    
    def plot_consistency_by_season(self):
        """
        ç»˜åˆ¶å„èµ›å­£ä¸€è‡´æ€§ç®±çº¿å›¾
        """
        weekly = self.results.groupby(['season', 'week']).first().reset_index()
        
        fig, ax = plt.subplots(figsize=(14, 6))
        
        seasons = sorted(weekly['season'].unique())
        data = [weekly[weekly['season'] == s]['consistency_score'].values for s in seasons]
        
        bp = ax.boxplot(data, patch_artist=True)
        
        # è®¾ç½®é¢œè‰²
        colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(seasons)))
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        ax.set_xticklabels([f'S{s}' for s in seasons], fontsize=9, rotation=45)
        ax.set_xlabel('Season', fontsize=12)
        ax.set_ylabel('Consistency Score', fontsize=12)
        ax.set_title('Consistency Score by Season', fontsize=14, fontweight='bold')
        ax.axhline(y=0.5, linestyle='--', color='red', alpha=0.5, label='Threshold (0.5)')
        ax.legend()
        
        plt.tight_layout()
        output_path = os.path.join(self.output_dir, 'consistency_by_season.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"ğŸ“¦ ç®±çº¿å›¾å·²ä¿å­˜: {output_path}")
    
    def generate_all_visualizations(self) -> None:
        """ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
        print("\n" + "=" * 60)
        print("  ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ (Matplotlib)")
        print("=" * 60)
        
        # 1. Top é€‰æ‰‹ ELO è½¨è¿¹ï¼ˆæŒ‰æ¯”èµ›å‘¨æ•°å¯¹é½ï¼‰
        self.plot_elo_trajectories(top_n=12)
        
        # 2. æœ€è¿‘3ä¸ªèµ›å­£çš„å•ç‹¬ ELO è½¨è¿¹å›¾
        seasons = sorted(self.results['season'].unique())[-3:]
        for s in seasons:
            self.plot_elo_by_season(s, top_n=8)
        
        # 3. æœ€è¿‘3ä¸ªèµ›å­£çš„çƒ­åŠ›å›¾
        for s in seasons:
            self.plot_fan_vote_heatmap(s)
        
        # 4. æ¨¡å‹è¯Šæ–­
        self.plot_model_diagnostics()
        
        # 5. èµ›å­£å¯¹æ¯”é›·è¾¾
        self.plot_season_comparison_radar()
        
        # 6. æœ€ç»ˆæ’å
        self.plot_final_rankings(top_n=25)
        
        # 7. ELO åˆ†å¸ƒ
        self.plot_elo_distribution()
        
        # 8. å„èµ›å­£ä¸€è‡´æ€§ç®±çº¿å›¾
        self.plot_consistency_by_season()
        
        # 9. ç¤ºä¾‹æ·˜æ±°æ¦‚ç‡å›¾
        if self.estimator.weekly_distributions:
            last_dist = self.estimator.weekly_distributions[-10]
            self.plot_elimination_probability(last_dist['season'], last_dist['week'])
        
        print(f"\nâœ… æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜è‡³ '{self.output_dir}' ç›®å½•")


# ============== ä¸»ç¨‹åºå…¥å£ ==============

def main():
    """ä¸»è¿è¡Œç¨‹åº"""
    import time
    
    input_csv = 'cleaned_weekly_data.csv'
    
    if not os.path.exists(input_csv):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {input_csv}")
        return
    
    print("=" * 70)
    print("  è´å¶æ–¯ ELO + é«˜çº§è’™ç‰¹å¡æ´›ç²‰ä¸æŠ•ç¥¨é€†å‘æ¨ç®—ç³»ç»Ÿ v2.0")
    print("=" * 70)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    df_cleaned = pd.read_csv(input_csv)
    print(f"   æ•°æ®è§„æ¨¡: {len(df_cleaned):,} è¡Œ")
    print(f"   èµ›å­£æ•°é‡: {df_cleaned['season'].nunique()}")
    print(f"   é€‰æ‰‹æ•°é‡: {df_cleaned['name'].nunique()}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    estimator = BayesianEloEstimator(
        base_k_factor=48.0,
        temperature=100.0,
        n_simulations=3000,
        noise_std=0.10,
        judge_weight=0.5,
        rd_decay=0.95,
        use_adaptive_params=True,
        memory_decay=0.92
    )
    
    backend = 'Numba JIT åŠ é€Ÿ' if NUMBA_AVAILABLE else 'çº¯ NumPy'
    print(f"\nâš¡ è®¡ç®—åç«¯: {backend}")
    print(f"ğŸ“ ç®—æ³•ç‰¹æ€§: è´å¶æ–¯æ›´æ–° + åˆ†å±‚è’™ç‰¹å¡æ´› + Glicko-2 é£æ ¼ RD")
    
    # è¿è¡Œæ¨æ–­
    print("\nğŸ”„ å¼€å§‹é€†å‘æ¨ç®—ç²‰ä¸æŠ•ç¥¨...")
    start_time = time.perf_counter()
    
    final_results = estimator.run_inference(df_cleaned)
    
    elapsed = time.perf_counter() - start_time
    
    # ä¿å­˜ç»“æœ
    output_file = 'fan_vote_estimates_weekly.csv'
    final_results.to_csv(output_file, index=False, float_format='%.6f')
    
    # è¾“å‡ºç»Ÿè®¡
    stats = estimator.get_statistics()
    print(f"\nâœ… æ¨æ–­å®Œæˆ!")
    print(f"   è€—æ—¶: {elapsed:.2f} ç§’")
    print(f"   æ€»æ¨¡æ‹Ÿæ¬¡æ•°: {stats['total_simulations']:,}")
    print(f"   é€‰æ‰‹æ€»æ•°: {stats['total_contestants']}")
    print(f"   å¹³å‡ ELO: {stats['avg_elo']:.1f} Â± {stats['elo_std']:.1f}")
    
    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    
    # æ¨¡å‹è¯„ä¼°
    print("\n" + "=" * 70)
    print("  æ¨¡å‹è¯„ä¼°æŒ‡æ ‡")
    print("=" * 70)
    weekly = final_results.groupby(['season', 'week']).first()
    print(f"   å¹³å‡ä¸€è‡´æ€§åˆ†æ•°: {weekly['consistency_score'].mean():.4f}")
    print(f"   å¹³å‡ç¡®å®šæ€§åˆ†æ•°: {weekly['certainty_score'].mean():.4f}")
    print(f"   å¹³å‡ KL æ•£åº¦: {weekly['kl_divergence'].mean():.4f}")
    print(f"   ä¸€è‡´æ€§ > 0.5 çš„å‘¨æ•°æ¯”ä¾‹: {(weekly['consistency_score'] > 0.5).mean():.2%}")
    
    # Top 10 æ’å
    print("\n" + "=" * 70)
    print("  Top 10 é€‰æ‰‹ (æœ€ç»ˆ ELO æ’å)")
    print("=" * 70)
    rankings = estimator.get_final_rankings()
    print(rankings.head(10).to_string(index=False))
    
    # ç”Ÿæˆå¯è§†åŒ–
    visualizer = EloVisualizer(estimator, final_results)
    visualizer.generate_all_visualizations()


if __name__ == "__main__":
    main()